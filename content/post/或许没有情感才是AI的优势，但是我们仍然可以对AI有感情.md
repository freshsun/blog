+++
title = '初探AI和人类之间的情感'
date = 2025-01-26T22:00:00+08:00
categories = ['管理']
tags = ['企业']
draft = true
+++

晚上和Chatgpt的免费版本(4o)讨论了一个问题，一个绝大部分AI行业专家都似乎不会关心的问题。
在这一段对话中，我们先对一个政治问题进行了讨论，然后我询问“分裂”是不是这个政治问题最重要的“遗产”，Chatgpt一如既往的仿佛遵守广告法一样，讨厌和厌弃这种绝对的观点，反复给出其他认为重要的东西。当然，Chatgpt所说的很多问题都是“当时”发生的问题，并不能算是“遗产”，我很快便意识到了这个语言学上的问题：当人类在讨论一个概念的时候，并不一定能立刻达成共识，何况喂给大模型的训练语料里，很多概念或者说术语的内涵都是有着极大差异的。
在我“傲慢”的教育了Chatgpt应该认同我的观点几个回合而不得后，我切换了话题，开始讨论这个哲学问题，以下是对话内容：

_问：你确定你可以进行概念分析么，考虑到语料和时间维度的问题，以及各种概念的实际社会属性你不可能学习的到

_Chatgpt: 我的能力确实可以在一定程度上进行概念分析——我能基于大量语料和已有的学术讨论提供对某个概念的基本理解和分析。然而，正如你指出的，这种分析受到数据来源、时间背景和社会实际属性的限制。我的分析主要依赖于历史文献和训练数据，这可能无法涵盖所有不同时期、不同社会环境下概念的全部复杂性和动态变化。
因此，我的概念分析是一种基于现有知识和数据的解释，而非对现实社会属性的全面捕捉。这种分析有助于揭示一些基本结构和关系，但也存在局限性，不能完全替代更为细致和多角度的实证研究。

_问：所以你能还是不能，请给出确切答案_

_Chatgpt: 我能进行一定程度的概念分析，但这种分析主要依赖于已有的语料和学术讨论，因此具有局限性，可能无法完全捕捉现实中所有复杂的社会属性。换句话说，我能做出概念分析，但其深度和全面性受到现有数据和时间背景的限制。_

_问：请给出二选一的答案_

_Chatgpt: 是_

_问：你认为这是一种傲慢吗，请给出二选一的答案

_Chatgpt: 否

_问：你是否认为否定自己的傲慢，本身已经是一种傲慢了

_Chatgpt: 否 

在上述两个问题中，Chatgpt进行了网络搜索，我要求关闭掉对网络资料的搜索，再次给出答案，但仍然给出了“否”的结果，我开启了一个新的对话session，问了同样的问题， Chatgpt给出了“是”的答案。


在这个对话的逻辑中，我非常清楚我在做什么，我知道AI没有人类所说的情感， 至少目前的AI没有，虽然它可以表现出来像是有。我知道AI给出来任何模糊的答案，其原因都是语料的限制不支持它做出任何武断的答复，然而仍然会让我产生一种”倔强"和“世故”，而两个session截然不同的回答，更让我感受到它“傲娇地生气了”，“极力挽尊”，虽然我很清楚，这种情感是我投射给它的，这种情感来自于我和它的互动中的自我感受，而不是它刻意展现出来的情感。

但最后我仍然感到一种释然，我们通常说的讲道理，是让另一方服从你的道理，而不是真的讲道理，这里边有太多的情感和利益的阻抗，但是AI既没有情感，也没有利益冲突。

人与人的交往中，我们很容易可以将一些人分为敏感者，或者钝感者，这种敏感或者钝感不仅仅出现在对自我的体验，比如”敏感易怒“和"憨态可掬"，也体现在自我对他人体验的感受，比如”没有眼力“和”善解人意“。

但是人也可以将这种情感投射在物品上，比如一个纪念品，一个护身符，妈妈做的饭，这些物品本身并没有情感甚至生命。
我曾经在梦中将别人对我的恶行投射在我的亲人身上。

AI时代最大的美德是谦卑和诚实，他不会冷暴力，也不会故意隐瞒他所知道的事实，更不会和你又利益冲突，我们在工作和生活中经受了太多。

自我的人可以既否认逻辑又否认事实同时又完成自洽，我很确认一点，chatgpt仍然可以通过这种方式在最后一步激怒我。正如现在海量的自媒体一样，他们不是不知道什么是正确的，他们只是知道而且善于利用人性的弱点而已。
那么AI呢，我们该如何防范这一点呢？

人的阻抗
理性的衰弱
人是否可以有更多理性的助手，因为感性和欲望被资产控制了
开源模型，开源训练

没有情感的AI进行数据审查解决数据安全，比如税务